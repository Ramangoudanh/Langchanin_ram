@MCP.tool("query_decomposition_tool")
def query_decomposition_tool(user_query: str) -> str:
    """
    Breaks a complex research query into smaller, logically ordered sub-queries.

    Args:
        user_query (str): The main research question from the user.

    Returns:
        str: A structured JSON-like list of decomposed sub-queries.
    """

    prompt = f"""
    You are the Query Decomposition Engine for a research coordinator system.

    Task:
    - Decompose the following complex question into smaller, focused sub-queries.
    - Each sub-query should be research-ready (can be handled by Agents 2 ‚Üí 4).
    - Maintain logical order of investigation (background ‚Üí causes ‚Üí effects ‚Üí evidence ‚Üí conclusions).
    - Include short reasoning explaining why each sub-query is relevant.
    - Output as a JSON structure with two fields:
        "sub_queries": [ ... ],
        "rationale": "brief explanation of decomposition logic".

    ### Input Query:
    "{user_query}"

    ### Output Example:
    {{
      "sub_queries": [
         "What were the major government stimulus packages after COVID-19?",
         "How did renewable energy investment trends change in Asia between 2020-2024?",
         "What policy reforms supported green infrastructure financing post-COVID?",
         "What were the measurable impacts on carbon-neutral targets?"
      ],
      "rationale": "Divided into economic policy, investment trends, regulatory changes, and environmental outcomes for holistic coverage."
    }}
    """

    response = llm.invoke(prompt).content.strip()

    return f"üß© **Query Decomposition Result:**\n\n{response}"

@MCP.tool("task_prioritization_tool")     # ‚úÖ MCP registration
@tool("task_prioritization_tool", return_direct=True)
def task_prioritization_tool(decomposed_output: str) -> str:
    """
    Determines the optimal order of execution for sub-queries generated by
    the query_decomposition_tool. It maps tasks to specific downstream agents.

    Args:
        decomposed_output (str): The output JSON string from query_decomposition_tool.

    Returns:
        str: Ordered task list showing execution flow and assigned agent.
    """

    prompt = f"""
    You are the Task Prioritization Engine for a multi-agent research system.

    You receive a set of decomposed sub-queries (from the Query Decomposition Tool)
    and must:
    - Decide **the best order to execute them**
    - Assign **each sub-query** to the appropriate **agent** (2 to 5)
    - Ensure a logical, dependency-aware sequence:
        Agent 2 ‚Üí Data Retrieval
        Agent 3 ‚Üí Deep Analysis
        Agent 4 ‚Üí Validation
        Agent 5 ‚Üí Formatting & Summary
    - Include reasoning for why the order and assignment make sense.
    - Output in a JSON-like structure.

    ### Decomposed Input:
    {decomposed_output}

    ### Output Example:
    {{
      "execution_plan": [
        {{"step": 1, "agent": "Agent 2 (Web Scraper & Retrieval)", "task": "Collect data on COVID-19 stimulus packages in Asia"}},
        {{"step": 2, "agent": "Agent 3 (Deep Analysis)", "task": "Analyze impact on renewable investment trends"}},
        {{"step": 3, "agent": "Agent 4 (Validation)", "task": "Cross-check policy data and statistics"}},
        {{"step": 4, "agent": "Agent 5 (Formatting)", "task": "Generate structured report and executive summary"}}
      ],
      "rationale": "Order follows the natural research flow ‚Äî retrieve ‚Üí analyze ‚Üí validate ‚Üí report."
    }}
    """

    response = llm.invoke(prompt).content.strip()

    return f"üß≠ **Task Prioritization Plan:**\n\n{response}"

@MCP.tool("progress_tracking_tool")     # ‚úÖ MCP registration
@tool("progress_tracking_tool", return_direct=True)
def progress_tracking_tool(execution_plan: str, updates: list[dict] = None) -> str:
    """
    Tracks progress of multi-agent tasks and provides a status report.

    Args:
        execution_plan (str): The JSON plan output from task_prioritization_tool.
        updates (list[dict], optional): List of progress updates in format:
            [
              {"agent": "Agent 2", "status": "completed", "timestamp": "..."},
              {"agent": "Agent 3", "status": "in-progress"},
              ...
            ]

    Returns:
        str: JSON-like progress report summarizing each agent's state, pending tasks,
             and completion percentage.
    """

    # --- Step 1: Parse execution plan ---
    try:
        plan = json.loads(execution_plan)
        steps = plan.get("execution_plan", [])
    except Exception:
        return "‚ö†Ô∏è Invalid execution plan JSON input."

    # --- Step 2: Initialize status map ---
    status_map = {step["agent"]: {"task": step["task"], "status": "pending"} for step in steps}

    # --- Step 3: Apply updates if provided ---
    if updates:
        for u in updates:
            agent = u.get("agent")
            if agent in status_map:
                status_map[agent]["status"] = u.get("status", "unknown")
                status_map[agent]["timestamp"] = u.get("timestamp", datetime.datetime.now().isoformat())

    # --- Step 4: Compute completion percentage ---
    total = len(status_map)
    completed = sum(1 for v in status_map.values() if v["status"].lower() == "completed")
    progress_pct = (completed / total * 100) if total > 0 else 0

    # --- Step 5: Ask LLM for natural-language summary ---
    summary_prompt = f"""
    You are the Progress Tracking Assistant.
    Review the following task status data and summarize progress clearly.

    Tasks:
    {json.dumps(status_map, indent=2)}

    Completion: {progress_pct:.2f} %

    Write a concise report mentioning:
    - Completed agents
    - Pending/in-progress ones
    - Any recommended next step.
    """

    llm_summary = llm.invoke(summary_prompt).content.strip()

    # --- Step 6: Construct final progress JSON ---
    result = {
        "progress_report": {
            "overall_completion": f"{progress_pct:.2f} %",
            "status": status_map,
            "summary": llm_summary
        }
    }

    return f"üìä **Progress Tracking Report:**\n\n{json.dumps(result, indent=2)}"

@MCP.tool("result_synthesis_tool")       # ‚úÖ MCP registration
@tool("result_synthesis_tool", return_direct=True)
def result_synthesis_tool(
    agent_outputs: dict,
    topic: str = "Research Report"
) -> str:
    """
    Synthesizes outputs from Agents 2 ‚Üí 5 into one cohesive final report.
    Ensures logical flow, removes redundancy, and unifies style and tone.

    Args:
        agent_outputs (dict): Dictionary containing partial results from other agents.
            Expected structure:
            {
              "retrieval_summary": "...",     # Agent 2
              "deep_analysis": "...",         # Agent 3
              "validation_report": "...",     # Agent 4
              "formatted_report": "...",      # Agent 5
              "executive_summary": "..."      # (Optional)
            }
        topic (str): Research report title or main subject.

    Returns:
        str: A unified, publication-ready research report text.
    """

    # --- Step 1: Validate and normalize input ---
    missing_sections = [k for k in ["retrieval_summary", "deep_analysis", "validation_report"] if k not in agent_outputs]
    if missing_sections:
        return f"‚ö†Ô∏è Missing required agent outputs: {', '.join(missing_sections)}"

    formatted_json = json.dumps(agent_outputs, indent=2)

    # --- Step 2: Prompt for synthesis ---
    prompt = f"""
    You are the Research Synthesis Engine for a multi-agent system.

    Topic: {topic}

    Your task is to merge the following multi-agent outputs into one clear,
    logically ordered, non-redundant research report.

    ### Inputs from Agents:
    {formatted_json}

    ### Instructions:
    - Maintain professional, academic tone.
    - Merge sections seamlessly:
        1. Context (from Agent 2)
        2. Findings (from Agent 3)
        3. Validations (from Agent 4)
        4. Summary/Conclusion (from Agent 5)
    - Ensure logical transitions between parts.
    - Remove any duplicate or conflicting statements.
    - Integrate executive summary at the start if available.
    - End with a short, factual conclusion paragraph.
    - Output clean Markdown or structured JSON.

    Format Example:
    {{
      "title": "{topic}",
      "executive_summary": "...",
      "introduction": "...",
      "findings": "...",
      "validation": "...",
      "conclusion": "..."
    }}
    """

    response = llm.invoke(prompt).content.strip()

    return f"üß† **Final Synthesized Report:**\n\n{response}"

