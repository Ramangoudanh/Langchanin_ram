@MCP.tool("causal_reasoning_tool")  # <-- MCP registration for interoperability
@tool("causal_reasoning_tool", return_direct=True)
def causal_reasoning_tool(topic: str, k: int = 5) -> str:
    """
    Detects and explains cause-effect relationships for a given topic or event.

    Steps:
      1. Retrieves relevant data/documents from PGVector.
      2. Extracts causal connectors (e.g. "because", "due to", "led to").
      3. Uses LLM reasoning to construct a cause-effect chain.
      4. Outputs both textual explanation and structured reasoning graph.

    Args:
        topic (str): Subject/event to analyze causality for.
        k (int): Number of top documents to analyze.

    Returns:
        str: Structured causal reasoning summary.
    """

    # --- Step 1: Retrieve contextual evidence ---
    docs = vector_store.similarity_search(topic, k=k)
    evidence_text = "\n".join([d.page_content[:500] for d in docs])

    # --- Step 2: Extract direct causal cues from text ---
    causal_snippets = []
    for sentence in evidence_text.split("."):
        if any(connector in sentence.lower() for connector in ["because", "due to", "led to", "as a result", "therefore"]):
            causal_snippets.append(sentence.strip())

    causal_text = "\n".join(causal_snippets[:10]) if causal_snippets else "No explicit causal statements detected."

    # --- Step 3: LLM-based causal inference ---
    prompt = f"""
    You are the Causal Reasoning Engine.

    Analyze the following topic for cause-effect relationships.

    Topic: {topic}

    Relevant text evidence:
    {evidence_text}

    Extracted causal clues:
    {causal_text}

    Tasks:
      1. Identify primary causes and their effects.
      2. Describe causal chain (A â†’ B â†’ C) if present.
      3. Summarize key drivers behind the observed outcomes.
      4. Estimate causal confidence (0â€“1).
      5. Output in this format:

      **Causal Factors:** ...
      **Effects/Outcomes:** ...
      **Causal Chain:** ...
      **Summary:** ...
      **Confidence:** ...
    """

    response = llm.invoke(prompt).content

    # --- Step 4: Parse confidence if mentioned ---
    match = re.search(r"(\d\.\d+)", response)
    conf_score = float(match.group(1)) if match else 0.75

    return (
        f"ðŸ”— Causal Reasoning for: '{topic}'\n"
        f"Confidence â‰ˆ {conf_score:.2f}\n\n"
        f"{response.strip()}"
    )
