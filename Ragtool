from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores.pgvector import PGVector
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain.tools import tool

@tool("RagSearchTool", return_direct=True)
def vector_search(action: str, reminder: str = None) -> str:
    """
    Retrieves and summarizes context from stored documents using PGVector and LCEL (LangChain Expression Language).
    """

    # Step 1: Setup embeddings
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # Step 2: Connect to PGVector store
    connection_string = "postgresql+psycopg://username:password@localhost:5432/vector_db"
    collection_name = "documents_collection"

    vector_store = PGVector(
        connection=connection_string,
        embeddings=embeddings,
        collection_name=collection_name,
        use_jsonb=True,
    )

    # Step 3: Create retriever
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})

    # Step 4: Define LLM
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

    # Step 5: Define the RAG prompt
    qa_prompt = ChatPromptTemplate.from_template(
        """You are a helpful assistant.
        Use the following context to answer the question.

        Context:
        {context}

        Question: {question}

        Give a short, factual, and clear answer."""
    )

    # Step 6: Build RAG pipeline using LCEL
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | qa_prompt
        | llm
        | StrOutputParser()
    )

    # Step 7: Run the RAG process
    query = action if reminder is None else f"{action}. Additional context: {reminder}"
    response = rag_chain.invoke(query)

    return response
def safe_load_json(path):
    try:
        with open(path, "r") as f:
            data = json.load(f)
            if not isinstance(data, list):
                return []
            return data
    except (json.JSONDecodeError, FileNotFoundError):
        # if file empty or invalid JSON, reset it
        with open(path, "w") as f:
            json.dump([], f)
        return []

"""
    Manage reminders.  
    Use this tool to ADD, LIST, or DELETE reminders.

    Parameters:
    - action: One of ["add", "list", "delete"].
      Example: "add" to add a reminder, "list" to see all, "delete" to remove by text.
    - reminder: The reminder text (required for add/delete).
    
    Examples:
    - Add a reminder: action="add", reminder="Call mom at 5 PM"
    - List all reminders: action="list"
    - Delete a reminder: action="delete", reminder="Call mom"
    """




import json
import os
from langchain.tools import tool
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser

DATA_PATH = "data/reminders.json"
os.makedirs("data", exist_ok=True)

if not os.path.exists(DATA_PATH):
    with open(DATA_PATH, "w") as f:
        json.dump([], f)

def safe_load_json():
    try:
        with open(DATA_PATH, "r") as f:
            data = json.load(f)
            if not isinstance(data, list):
                return []
            return data
    except (json.JSONDecodeError, FileNotFoundError):
        with open(DATA_PATH, "w") as f:
            json.dump([], f)
        return []

def save_json(data):
    with open(DATA_PATH, "w") as f:
        json.dump(data, f, indent=2)

# Setup a minimal LLM call
llm = ChatOpenAI(temperature=0)
parser = StrOutputParser()

delete_prompt = PromptTemplate.from_template("""
You are a helpful assistant managing reminders.
You are given the user's delete command and a list of reminders.

Find which reminder in the list best matches what the user wants to delete.
If you think none of the reminders match, just return "None".

Return exactly the reminder text from the list (must match one in the list) or "None".

User request: {user_input}

Reminders:
{reminders}

Output only the reminder string to delete or "None".
""")

@tool("reminder_tool", return_direct=True)
def reminder_tool(action: str, reminder: str = None) -> str:
    """
    Smart Reminder Manager.
    Supports: add, list, delete
    - Add: action='add', reminder='text'
    - List: action='list'
    - Delete: action='delete', reminder='user text' (uses LLM to find best match)
    """

    reminders = safe_load_json()

    # ADD
    if action == "add" and reminder:
        reminders.append(reminder)
        save_json(reminders)
        return f"âœ… Reminder added: {reminder}"

    # LIST
    elif action == "list":
        if not reminders:
            return "ğŸ“­ No reminders found."
        return "ğŸ“ Reminders:\n" + "\n".join([f"{i+1}. {r}" for i, r in enumerate(reminders)])

    # DELETE (Smart with LLM)
    elif action == "delete" and reminder:
        if not reminders:
            return "ğŸ“­ No reminders available to delete."

        # Step 1: Ask LLM which one to delete
        prompt_text = delete_prompt.format(user_input=reminder, reminders=json.dumps(reminders, indent=2))
        llm_output = llm.invoke(prompt_text)
        match = parser.invoke(llm_output).strip().strip('"')

        if match == "None" or match not in reminders:
            return f"âš ï¸ No close reminder found matching: '{reminder}'"

        # Step 2: Delete matched reminder
        reminders.remove(match)
        save_json(reminders)
        return f"ğŸ—‘ï¸ Deleted reminder: {match}"

    return "âŒ Invalid action or missing reminder."





import os
import uuid
from langchain.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain.docstore.document import Document
from langchain.tools import tool
from dotenv import load_dotenv

# Load environment
load_dotenv()

# --- Configuration ---
connection_string = os.getenv("DATABASE_URL")  # e.g. postgresql+psycopg2://user:pass@localhost:5432/todo_db
collection_name = "todo_collection"

# --- Vector Store Setup ---
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

vector_store = PGVector(
    connection_string=connection_string,
    embedding_function=embeddings,
    collection_name=collection_name,
    use_jsonb=True
)

# --- LangChain Tool ---
@tool("todo_pgvector_tool", return_direct=True)
def todo_pgvector_tool(action: str, task: str = None) -> str:
    """
    Manage a semantic To-Do list using PGVector.
    Supports:
      - Add: action='add', task='Task text'
      - List: action='list'
      - Delete: action='delete', task='Task text' (semantic match + delete by ID)
    """

    # --- ADD ---
    if action == "add" and task:
        doc_id = str(uuid.uuid4())
        doc = Document(page_content=task, metadata={"id": doc_id})
        vector_store.add_documents([doc], ids=[doc_id])
        return f"âœ… Added ToDo: '{task}' (id={doc_id})"

    # --- LIST ---
    elif action == "list":
        # NOTE: LangChain PGVector doesnâ€™t expose a direct â€œlist allâ€ API.
        # We'll simulate by searching with an empty query and large k.
        results = vector_store.similarity_search(query="", k=100)
        if not results:
            return "ğŸ“­ No ToDos found."
        todos = [f"{i+1}. {doc.page_content} (id={doc.metadata.get('id','?')})" for i, doc in enumerate(results)]
        return "ğŸ“ Your To-Do List:\n" + "\n".join(todos)

    # --- DELETE (semantic match) ---
    elif action == "delete" and task:
        # Step 1: Find the closest matching ToDo via similarity search
        results = vector_store.similarity_search(query=task, k=1)
        if not results:
            return f"âš ï¸ No ToDo found similar to '{task}'."

        best_doc = results[0]
        doc_id = best_doc.metadata.get("id")

        if not doc_id:
            return f"âš ï¸ Could not find ID for the matched task: '{best_doc.page_content}'."

        # Step 2: Delete that ToDo by ID
        vector_store.delete(ids=[doc_id])
        return f"ğŸ—‘ï¸ Deleted closest ToDo: '{best_doc.page_content}' (id={doc_id})"

    return "âŒ Invalid action or missing task."
